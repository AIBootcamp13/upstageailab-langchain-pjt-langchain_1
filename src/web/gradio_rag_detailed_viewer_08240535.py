#!/usr/bin/env python3
"""
Gradio RAG ìƒì„¸ ê²°ê³¼ ë·°ì–´ v08240535
ì§ˆë¬¸ë³„ LLM ëª¨ë¸, RAG ì „í›„ ë‹µë³€, ìƒì„¸ ì ìˆ˜ë¥¼ ì„ íƒí•´ì„œ ë³¼ ìˆ˜ ìˆëŠ” ì¸í„°ë™í‹°ë¸Œ ë·°ì–´
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

import gradio as gr
import pandas as pd

# ê¸€ë¡œë²Œ ë³€ìˆ˜
analysis_results = None
current_data_file = None

def load_analysis_results(json_file_path: str = None) -> Optional[Dict]:
    """ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ ë¡œë“œ"""
    global analysis_results
    
    if json_file_path is None:
        # ê¸°ë³¸ ê²½ë¡œì—ì„œ ê°€ì¥ ìµœê·¼ íŒŒì¼ ì°¾ê¸°
        results_dir = Path("results/rag_improvement_v08240535")
        if results_dir.exists():
            json_files = list(results_dir.glob("rag_improvement_v08240535_*.json"))
            if json_files:
                json_file_path = str(max(json_files, key=lambda x: x.stat().st_mtime))
            else:
                return None
        else:
            return None
    
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            analysis_results = json.load(f)
        return analysis_results
    except Exception as e:
        print(f"ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def get_question_list() -> List[str]:
    """ì§ˆë¬¸ ëª©ë¡ ë°˜í™˜"""
    if not analysis_results:
        return []
    
    questions = analysis_results.get('questions', {})
    question_list = []
    
    for q_id, q_data in questions.items():
        question_text = q_data.get('question', 'ì§ˆë¬¸ ì—†ìŒ')
        question_list.append(f"{q_id.upper()}: {question_text[:50]}...")
    
    return question_list

def get_question_details(selected_question: str) -> Tuple[str, List[str]]:
    """ì„ íƒëœ ì§ˆë¬¸ì˜ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
    if not analysis_results or not selected_question:
        return "ì§ˆë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", []
    
    # ì§ˆë¬¸ ID ì¶”ì¶œ
    q_id = selected_question.split(':')[0].lower()
    
    questions = analysis_results.get('questions', {})
    if q_id not in questions:
        return "í•´ë‹¹ ì§ˆë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
    
    q_data = questions[q_id]
    question_text = q_data.get('question', 'ì§ˆë¬¸ ì—†ìŒ')
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
    available_models = list(q_data.get('responses', {}).keys())
    
    return question_text, available_models

def get_model_response_comparison(selected_question: str, selected_model: str) -> Tuple[str, str, str, str]:
    """ì„ íƒëœ ì§ˆë¬¸ê³¼ ëª¨ë¸ì˜ ìˆœìˆ˜/RAG ë‹µë³€ ë¹„êµ"""
    if not analysis_results or not selected_question or not selected_model:
        return "ë°ì´í„° ì—†ìŒ", "ë°ì´í„° ì—†ìŒ", "ì ìˆ˜ ì •ë³´ ì—†ìŒ", "ë¶„ì„ ì—†ìŒ"
    
    # ì§ˆë¬¸ ID ì¶”ì¶œ
    q_id = selected_question.split(':')[0].lower()
    
    questions = analysis_results.get('questions', {})
    if q_id not in questions:
        return "ì§ˆë¬¸ ë°ì´í„° ì—†ìŒ", "ì§ˆë¬¸ ë°ì´í„° ì—†ìŒ", "ì ìˆ˜ ì •ë³´ ì—†ìŒ", "ë¶„ì„ ì—†ìŒ"
    
    q_data = questions[q_id]
    
    # ëª¨ë¸ ì‘ë‹µ ë°ì´í„°
    model_responses = q_data.get('responses', {}).get(selected_model, {})
    if not model_responses:
        return "ëª¨ë¸ ë°ì´í„° ì—†ìŒ", "ëª¨ë¸ ë°ì´í„° ì—†ìŒ", "ì ìˆ˜ ì •ë³´ ì—†ìŒ", "ë¶„ì„ ì—†ìŒ"
    
    # ìˆœìˆ˜ LLM ì‘ë‹µ
    pure_response = model_responses.get('pure', {})
    pure_answer = pure_response.get('answer', 'ì‘ë‹µ ì—†ìŒ')
    pure_info = f"""
**ìˆœìˆ˜ {selected_model} ì‘ë‹µ**
- ë‹µë³€ ê¸¸ì´: {pure_response.get('answer_length', 0)}ê¸€ì
- ë‹¨ì–´ ìˆ˜: {pure_response.get('word_count', 0)}ê°œ
- ì‘ë‹µ ì‹œê°„: {pure_response.get('response_time', 0):.2f}ì´ˆ
- ìƒíƒœ: {pure_response.get('status', 'unknown')}

**ë‹µë³€ ë‚´ìš©:**
{pure_answer}
    """.strip()
    
    # RAG ì‘ë‹µ
    rag_response = model_responses.get('rag', {})
    rag_answer = rag_response.get('answer', 'ì‘ë‹µ ì—†ìŒ')
    relevant_cases = rag_response.get('relevant_cases', [])
    rag_info = f"""
**RAG ê¸°ë°˜ {selected_model} ì‘ë‹µ**
- ë‹µë³€ ê¸¸ì´: {rag_response.get('answer_length', 0)}ê¸€ì
- ë‹¨ì–´ ìˆ˜: {rag_response.get('word_count', 0)}ê°œ
- ì‘ë‹µ ì‹œê°„: {rag_response.get('response_time', 0):.2f}ì´ˆ
- ì‚¬ìš©ëœ íŒë¡€: {rag_response.get('case_count', 0)}ê±´
- ìƒíƒœ: {rag_response.get('status', 'unknown')}

**í™œìš© íŒë¡€:** {', '.join(relevant_cases) if relevant_cases else 'ì—†ìŒ'}

**ë‹µë³€ ë‚´ìš©:**
{rag_answer}
    """.strip()
    
    # ê°œì„ ë„ ë¶„ì„
    improvements = q_data.get('improvements', {}).get(selected_model, {})
    improvement_score = improvements.get('overall_score', 0)
    analysis_text = improvements.get('analysis', 'ë¶„ì„ ì—†ìŒ')
    
    score_details = f"""
## ğŸ“Š RAG ê°œì„  ì ìˆ˜ ë¶„ì„

### ğŸ¯ ì „ì²´ ê°œì„  ì ìˆ˜: **{improvement_score:.1f}/100ì **

### ğŸ“ˆ ì„¸ë¶€ ì§€í‘œ
- **êµ¬ì²´ì„± ê°œì„ **: {improvements.get('specificity_improvement', 0)}ì  (ì‚¬ê±´ë²ˆí˜¸ ì¸ìš©)
- **ê·¼ê±° ê°•í™”**: {improvements.get('evidence_improvement', 0)}ì  (ë²•ë¥  í‚¤ì›Œë“œ)
- **ë‹µë³€ ê¸¸ì´ ë³€í™”**: {improvements.get('length_change', 0):+d}ê¸€ì
- **ë‹¨ì–´ ìˆ˜ ë³€í™”**: {improvements.get('word_count_change', 0):+d}ê°œ
- **ì‘ë‹µ ì‹œê°„ ë³€í™”**: {improvements.get('response_time_change', 0):+.2f}ì´ˆ
- **ë²•ë¥  í‚¤ì›Œë“œ ë°€ë„**: {improvements.get('legal_keyword_density', 0):.2f}/1000ê¸€ì

### ğŸ” ë¶„ì„ ê²°ê³¼
{analysis_text}
    """.strip()
    
    return pure_info, rag_info, score_details, analysis_text

def get_all_questions_summary() -> str:
    """ì „ì²´ ì§ˆë¬¸ ìš”ì•½ í†µê³„"""
    if not analysis_results:
        return "ë°ì´í„° ì—†ìŒ"
    
    summary = analysis_results.get('summary', {})
    
    summary_text = f"""
# ğŸ“Š ì „ì²´ ë¶„ì„ ìš”ì•½ (v08240535)

## ğŸ¯ ê¸°ë³¸ ì •ë³´
- **ë¶„ì„ ì‹œê°„**: {analysis_results.get('timestamp', 'N/A')}
- **ì´ ì§ˆë¬¸ ìˆ˜**: {analysis_results.get('total_questions', 0)}ê°œ
- **ë¶„ì„ ëª¨ë¸**: {', '.join(analysis_results.get('models', []))}
- **ì´ ì²˜ë¦¬ ì‹œê°„**: {analysis_results.get('total_processing_time', 0):.1f}ì´ˆ

## ğŸ† ëª¨ë¸ë³„ ì„±ëŠ¥ ìš”ì•½
"""
    
    model_averages = summary.get('model_averages', {})
    for model, data in model_averages.items():
        summary_text += f"""
### {model}
- **í‰ê·  ê°œì„  ì ìˆ˜**: {data.get('avg_improvement_score', 0):.1f}/100ì 
- **ìµœê³  ì ìˆ˜**: {data.get('best_score', 0):.1f}ì 
- **ìµœì € ì ìˆ˜**: {data.get('worst_score', 0):.1f}ì 
- **í‰ê·  ì‚¬ìš© íŒë¡€**: {data.get('avg_cases_used', 0):.1f}ê±´
- **í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì¦ê°€**: {data.get('avg_time_increase', 0):+.2f}ì´ˆ
"""
    
    # í†µê³„ì  ì‹ ë¢°ë„ ì •ë³´
    q_stats = summary.get('question_statistics', {})
    if q_stats:
        summary_text += f"""
## ğŸ”¬ í†µê³„ì  ì‹ ë¢°ë„ (30ê°œ ì§ˆë¬¸ ê¸°ë°˜)
- **ì´ í‰ê°€ ìˆ˜**: {q_stats.get('total_evaluations', 0)}íšŒ
- **ì „ì²´ í‰ê·  ì ìˆ˜**: {q_stats.get('overall_avg_score', 0):.1f}/100ì 
- **ì ìˆ˜ í‘œì¤€í¸ì°¨**: {q_stats.get('score_std_dev', 0):.2f}
- **ì‹ ë¢°ë„ ê°œì„ **: â­â­â­â­â­â­ (ê¸°ì¡´ ëŒ€ë¹„ 6ë°° í–¥ìƒ)
"""
    
    return summary_text

def create_comparison_table() -> str:
    """ëª¨ë¸ ë¹„êµ í…Œì´ë¸” ìƒì„±"""
    if not analysis_results:
        return "ë°ì´í„° ì—†ìŒ"
    
    questions = analysis_results.get('questions', {})
    
    table_data = []
    for q_id, q_data in questions.items():
        question_short = q_data.get('question', '')[:30] + "..."
        
        for model in ['GPT-4o', 'Claude-3.5']:
            if model in q_data.get('improvements', {}):
                improvement = q_data['improvements'][model]
                responses = q_data['responses'][model]
                
                table_data.append([
                    q_id.upper(),
                    question_short,
                    model,
                    f"{improvement.get('overall_score', 0):.1f}",
                    f"{responses['rag'].get('case_count', 0)}",
                    f"{improvement.get('response_time_change', 0):+.2f}ì´ˆ",
                    improvement.get('analysis', '')[:50] + "..."
                ])
    
    # í…Œì´ë¸” ìƒì„±
    headers = ["ì§ˆë¬¸ID", "ì§ˆë¬¸", "ëª¨ë¸", "ê°œì„ ì ìˆ˜", "íŒë¡€ìˆ˜", "ì‹œê°„ë³€í™”", "ë¶„ì„ê²°ê³¼"]
    
    table_md = "| " + " | ".join(headers) + " |\n"
    table_md += "|" + "|".join(["---"] * len(headers)) + "|\n"
    
    for row in table_data:
        table_md += "| " + " | ".join(row) + " |\n"
    
    return table_md

def refresh_data():
    """ë°ì´í„° ìƒˆë¡œê³ ì¹¨"""
    global analysis_results
    load_analysis_results()
    if analysis_results:
        return "âœ… ë°ì´í„° ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ", get_question_list(), get_all_questions_summary()
    else:
        return "âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨", [], "ë°ì´í„° ì—†ìŒ"

def create_gradio_interface():
    """Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    
    # ì´ˆê¸° ë°ì´í„° ë¡œë“œ
    load_analysis_results()
    
    with gr.Blocks(title="RAG ìƒì„¸ ê²°ê³¼ ë·°ì–´ v08240535", theme=gr.themes.Soft()) as interface:
        gr.Markdown("""
# ğŸ” RAG ìƒì„¸ ê²°ê³¼ ë·°ì–´ v08240535
        
ì§ˆë¬¸ë³„ë¡œ LLM ëª¨ë¸ì˜ RAG ì „í›„ ë‹µë³€ê³¼ ìƒì„¸ ì ìˆ˜ë¥¼ ë¹„êµí•´ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
30ê°œ ì§ˆë¬¸ Ã— 2ê°œ ëª¨ë¸ì˜ ëª¨ë“  ê²°ê³¼ë¥¼ ì¸í„°ë™í‹°ë¸Œí•˜ê²Œ íƒìƒ‰í•´ë³´ì„¸ìš”!
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ¯ ì§ˆë¬¸ ë° ëª¨ë¸ ì„ íƒ")
                
                refresh_btn = gr.Button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨", variant="secondary")
                status_text = gr.Textbox(
                    label="ìƒíƒœ",
                    value="ë°ì´í„° ë¡œë”© ì¤‘...",
                    interactive=False
                )
                
                question_dropdown = gr.Dropdown(
                    label="ğŸ“ ì§ˆë¬¸ ì„ íƒ",
                    choices=get_question_list(),
                    value=None,
                    interactive=True
                )
                
                model_dropdown = gr.Dropdown(
                    label="ğŸ¤– ëª¨ë¸ ì„ íƒ",
                    choices=[],
                    value=None,
                    interactive=True
                )
                
                selected_question_display = gr.Textbox(
                    label="ì„ íƒëœ ì§ˆë¬¸",
                    value="ì§ˆë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.",
                    interactive=False,
                    lines=3
                )
            
            with gr.Column(scale=2):
                gr.Markdown("## ğŸ“Š ì „ì²´ ë¶„ì„ ìš”ì•½")
                
                summary_display = gr.Markdown(
                    value=get_all_questions_summary()
                )
        
        # ë‹µë³€ ë¹„êµ ì„¹ì…˜
        gr.Markdown("## âš–ï¸ RAG ì „í›„ ë‹µë³€ ë¹„êµ")
        
        with gr.Row():
            with gr.Column():
                pure_response_display = gr.Markdown(
                    label="ìˆœìˆ˜ LLM ì‘ë‹µ",
                    value="ì§ˆë¬¸ê³¼ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
                )
            
            with gr.Column():
                rag_response_display = gr.Markdown(
                    label="RAG ê¸°ë°˜ ì‘ë‹µ",
                    value="ì§ˆë¬¸ê³¼ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
                )
        
        # ì ìˆ˜ ë¶„ì„ ì„¹ì…˜
        gr.Markdown("## ğŸ“ˆ ìƒì„¸ ì ìˆ˜ ë¶„ì„")
        
        with gr.Row():
            with gr.Column():
                score_analysis_display = gr.Markdown(
                    value="ì§ˆë¬¸ê³¼ ëª¨ë¸ì„ ì„ íƒí•˜ë©´ ìƒì„¸ ì ìˆ˜ê°€ í‘œì‹œë©ë‹ˆë‹¤."
                )
            
            with gr.Column():
                comparison_table_display = gr.Markdown(
                    label="ì „ì²´ ë¹„êµ í…Œì´ë¸”",
                    value=create_comparison_table()
                )
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        def update_question_details(selected_question):
            if selected_question:
                question_text, available_models = get_question_details(selected_question)
                return question_text, gr.update(choices=available_models, value=None)
            else:
                return "ì§ˆë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", gr.update(choices=[], value=None)
        
        def update_response_comparison(selected_question, selected_model):
            if selected_question and selected_model:
                pure_info, rag_info, score_details, analysis = get_model_response_comparison(
                    selected_question, selected_model
                )
                return pure_info, rag_info, score_details
            else:
                return "ì§ˆë¬¸ê³¼ ëª¨ë¸ì„ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.", "ì§ˆë¬¸ê³¼ ëª¨ë¸ì„ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.", "ì ìˆ˜ ì •ë³´ ì—†ìŒ"
        
        # ì§ˆë¬¸ ì„ íƒ ì‹œ ëª¨ë¸ ëª©ë¡ ì—…ë°ì´íŠ¸
        question_dropdown.change(
            fn=update_question_details,
            inputs=[question_dropdown],
            outputs=[selected_question_display, model_dropdown]
        )
        
        # ëª¨ë¸ ì„ íƒ ì‹œ ë‹µë³€ ë¹„êµ ì—…ë°ì´íŠ¸
        model_dropdown.change(
            fn=update_response_comparison,
            inputs=[question_dropdown, model_dropdown],
            outputs=[pure_response_display, rag_response_display, score_analysis_display]
        )
        
        # ë°ì´í„° ìƒˆë¡œê³ ì¹¨
        refresh_btn.click(
            fn=refresh_data,
            outputs=[status_text, question_dropdown, summary_display]
        )
        
        # ì´ˆê¸°í™”
        interface.load(
            fn=lambda: ("âœ… ë·°ì–´ ì¤€ë¹„ ì™„ë£Œ", get_question_list(), get_all_questions_summary(), create_comparison_table()),
            outputs=[status_text, question_dropdown, summary_display, comparison_table_display]
        )
    
    return interface

if __name__ == "__main__":
    # ì¸í„°í˜ì´ìŠ¤ ìƒì„± ë° ì‹¤í–‰
    interface = create_gradio_interface()
    
    print("ğŸ” RAG ìƒì„¸ ê²°ê³¼ ë·°ì–´ v08240535 ì‹œì‘")
    print("ğŸ“Š ì§ˆë¬¸ë³„ LLM ëª¨ë¸, RAG ì „í›„ ë‹µë³€, ìƒì„¸ ì ìˆ˜ ë¹„êµ ê°€ëŠ¥")
    print("ğŸŒ ì›¹ ì¸í„°í˜ì´ìŠ¤: http://localhost:7866")
    
    interface.launch(
        server_name="0.0.0.0",
        server_port=7866,
        share=False,
        show_error=True
    )